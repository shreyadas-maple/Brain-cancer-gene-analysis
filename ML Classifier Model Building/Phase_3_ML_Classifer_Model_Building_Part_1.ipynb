{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViDoyOIhFNEt"
      },
      "source": [
        "# Phase 3: ML Classifier Model Building Part 1\n",
        "**Shreya Das**\n",
        "\n",
        "This dataset was originally created to be used for machine learning, specifically a model used to predict which cancer type the sample originates from based on the gene expression. We want to create an ML model that correctly classifies the cancer type based on the gene expression.\n",
        "\n",
        "Before we start building out ML model, we need to figure out which ML model is the best for this dataset and the goal that we want to achieve. We will use the original dataset for this process.\n",
        "\n",
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaeF0VhQFNEu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G70oN7YwFNEu"
      },
      "source": [
        "Read the .csv file into the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVC6oQ_kFNEu"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/Brain_GSE50161.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZKPA-MjFNEu"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pRQ8A6OFNEv"
      },
      "source": [
        "We will now split the dataset into training data and test data from sklearn.model selection module. This is a crucial step as we need to first train our ML model on our data, but we also need to test how good the model is based on data that it has never seen. This is how we evaluate its performance in reality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaItlx6wFNEv"
      },
      "outputs": [],
      "source": [
        "# install lazypredict module if required\n",
        "!pip install lazypredict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og6UA3dOFNEv"
      },
      "outputs": [],
      "source": [
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBwZt0HIFNEv"
      },
      "source": [
        "We will keep the X data (independent variable) as the gene expression values of each of the genes. The Y data (dependent variable) is the cancer categories; this is the variable that the model will predict based on the gene expression levels of each gene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBnxYm0RFNEv"
      },
      "outputs": [],
      "source": [
        "# For the X variable we only want the gene expression values, not the samples and types\n",
        "selection = ['samples', 'type']\n",
        "\n",
        "# We exclude the columns we don't want which is the samples and types\n",
        "X = df.loc[:, ~df.columns.isin(selection)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WQwLls-FNEv"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDFFhkvoFNEv"
      },
      "outputs": [],
      "source": [
        "# Setting the Y variable to only include the types of cancer or categories\n",
        "Y = df['type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FnVeT1pFNEv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(np.unique(Y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvXg9xAbFNEv"
      },
      "source": [
        "Here we see that we have 5 unique categories: 4 cancer types and 1 normal type.\n",
        "\n",
        "We will be using a LabelEncoder ML model from sklearn module as the ML technique to label cancer types based on the gene expression level.\n",
        "\n",
        "The fit_transform() function allows labels to be encoded as numerical values; this way the encoder can easily understand that different categorical information based on numerical values rather than string category names. To human language, string category names means something; to a computer or machine it means just a string with different characters, so we can replace these categories with unique numerical values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4q3VSrwFNEv"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Put numerical values onto the unique type categories for the LabelEncoder to work with\n",
        "Y_encoded = le.fit_transform(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH7pAglHFNEv"
      },
      "source": [
        "We are now going to split the X and Y data into X-Y training and test data. Generally we keep the test data as 20% of our dataset and 80% is the tranining data, because we need to make sure our models are trained with as muck information as possible.\n",
        "\n",
        "The random_state variable is a numerical value provided to set a seed to the random generator, so that when we run this code again the X and Y train and test sets are not different everytime.\n",
        "\n",
        "We are using LazyClassifier to check the ML model performance of the ML models we may use based on the data we have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXYoAdGBFNEv"
      },
      "outputs": [],
      "source": [
        "# Splitting the data into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y_encoded, test_size=0.2, random_state=13)\n",
        "\n",
        "# Here is the LazyClassifier that we will use to check the model performance and use the data to fit to each of the models\n",
        "clf = LazyClassifier(verbose=1, ignore_warnings=True, custom_metric=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9ZOcBsIFNEw"
      },
      "source": [
        "Using the LazyClassifier we are going to get the models and predictions (classifications) based on the fitted X and Y data. This will take some time, so be patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ossir4UsFNEw"
      },
      "outputs": [],
      "source": [
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9iQ4bypFNEw"
      },
      "source": [
        "We will know see the model performance of each of the ML models for classification of the different cancer types.\n",
        "\n",
        "**Accuracy** This is the ratio of total number of correctly predicted classifications vs. the total number of classifications. 1.0 means perfect accuracy.\n",
        "\n",
        "**Balanced Accuracy** This is different metric used to evaluate model accuracy. It is different from accuracy such that it is not affected by the unequal number of samples in each group. This is important for our dataset since we have different number of samples in each sample type.\n",
        "\n",
        "**ROC AUC** This is a metric that helps us understand if a model can distinguish between 2 classes: positive and negative. A value closer to 1.0 is perfect classification, and 0.5 is random guessing. However, this is not relevant in our classification task since we have more types than just positive and negative.\n",
        "\n",
        "**F1 Score** This is a metric that combines precision and recall. Precision indicates the model's accuracy of predicting positive predictions. Recall indicates the model's ability to capture true positive predictions over number of actual positive predictions. A value close to 1.0 is best.\n",
        "\n",
        "**Time Taken** Is how long the model takes to finish predictions. We want a model that also takes the least amount of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFFF4BwVFNEw"
      },
      "outputs": [],
      "source": [
        "models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2A_RTtlHFNEw"
      },
      "outputs": [],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLWhyr8DFNEw"
      },
      "source": [
        "Looking at both the models (train data) and predictions (test data) we see that most models have the same performance. The top 3 models are **RidgeClassifierCV, Ridge Classifier, and ExtraTreesClassifier** across both accuracy, F1 score, and time taken.\n",
        "\n",
        "Based on this we will build out the top 3 models for this dataset and compare the predictions at the end. Particularly for this dataset we have ~54,000 genes for each sample, which can have complex patterns for each sample. We need to find the best model that can handle this much data and complaxity."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}